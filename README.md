---
title: 
layout: post
weight: 10
hidden: true
---

===


**Course**: DS   <br/>
**Mod**: Mod 3 Sec 23 V2         <br/>
**Topic**:  Naive Bayes Classifiers  <br/>
**Amount of time**: ~60 minutes <br/>
**Author**: Alison Peebles


Ported from the ds-lessons-starter repository
***

#### Lesson Summary:

This lesson reviews the concept of Naive Bayes Classifiers for document classification using a bag of words approach. It begins by reposing the general question of how to perform document classification and leads students through the concept by investigating word frequency of two corpuses. From there, students are led through coding said implementation before using sci-kit learn.

#### Topic:

Statistics: Bayes Theorem and Naive Bayes Classifiers

#### Prerequisite knowledge:

* Students should be able to calculate and apply conditional probability to word problems.
* Students should be able to define and apply Bayes' Theorem
* Students should have exposure to Naive Bayes Classifiers and their python implementations

#### Prequisite Learn-Materials:

[Bayes' Theorem](https://github.com/learn-co-curriculum/dsc-bayes-theorem)
[Bayes' Theorem - Lab](https://github.com/learn-co-curriculum/dsc-bayes-theorem-lab)

[The Monty Hall Problem - Lab](https://github.com/learn-co-curriculum/dsc-monty-hall-problem-lab)


[Bayesians vs Frequentists](https://github.com/learn-co-curriculum/dsc-bayesians-vs-frequentists)
[Classifiers with Bayes](https://github.com/learn-co-curriculum/dsc-classifiers-with-bayes)

[Document Classification with Naive Bayes](https://github.com/learn-co-curriculum/dsc-document-classification-with-naive-bayes)
[Document Classification with Naive Bayes - Lab](https://github.com/learn-co-curriculum/dsc-document-classification-with-naive-bayes-lab)


Recommended but more supplementary:

[Gaussian Naive Bayes](https://github.com/learn-co-curriculum/dsc-gaussian-naive-bayes)
[Gaussian Naive Bayes - Lab](https://github.com/learn-co-curriculum/dsc-gaussian-naive-bayes-lab)

[Maximum Likelihood Estimation (MLE)](https://github.com/learn-co-curriculum/dsc-mle)
[Maximum A Posteriori Estimation (MAP) and Multinomial Bayes](https://github.com/learn-co-curriculum/dsc-map-multinomial-bayes)

#### Post Learn-Materials:

It is recommended that students attempt these labs before class, but they can return to these lessons to further engage with the material from this lesson.

[Bayes' Theorem - Lab](https://github.com/learn-co-curriculum/dsc-bayes-theorem-lab)
[Gaussian Naive Bayes - Lab](https://github.com/learn-co-curriculum/dsc-gaussian-naive-bayes-lab)
[Document Classification with Naive Bayes - Lab](https://github.com/learn-co-curriculum/dsc-document-classification-with-naive-bayes-lab)



#### Learning goals for this lesson:


* Students will be able to apply Bayes Theorem to a word problem.
* Students will be able to compare and contrast Bayes Classifiers including Gaussian Naive Bayes and Bernoulli Naive Bayes.
* Students will be able to explain python code for implementing a Naive Bayes Classifier.


#### Relevant learning goals from Airtable: 

BAYES.1.rec4dX6d6f1cMFbcn Define Bayes Theorem in relation to conditional probabilities
BAYES.2.recHQkTu9DmwBs9Oj Use Bayes' Theorem to determine the probability of specific events
BAYES.2.recfnnQ5l74dxvAsD Identify examples of applications of Bayes' Theorem
BAYES.2.recfEgSB5kmXQQY0w Explain how to use the probabilities generated by Naive Bayes to make a classification
BAYES.2.recrWYWSfiarh0TTO Implement the Gaussian Naive Bayes Algorithm using numpy and scipy
BAYES.3.rec9xyzJewoWuvNrj Implement document classification using Naive Bayes


#### Materials
- Ipython notebook

#### Vocab / Concepts 

* Bayes Theorem
* Conditional Probability

#### Lesson Outline:

* Introduction 
	* Problem Posing: Document Classification
	* Laplacian Smoothing
* Likelihood
* Other Naive Bayes Classifiers
* Naive Bayes in Sklearn